import torch
import torch.nn as nn
import numpy as np
from torch.autograd import Variable
import torch.nn.functional as F
class DAR(object):
    '''
    输入进来的是一个batch的样本 对抗样本和双重对抗样本还有标签
    输出这个batch的损失
    '''
    def __init__(self,model,y,b):
        self.model = model
        self.celoss = nn.CrossEntropyLoss()
        self.klloss = nn.KLDivLoss(reduction='batchmean')
        self.y = y
        self.b = b
        
    def prob(self,X,Y):
        prob = self.model(X)
        prob=F.softmax(prob, dim=1)
        P_y_X=prob.gather(1, Y.view(-1,1))
        return P_y_X

    def loss(self,Y,X_nat,X_double_adv,prob_sum):#计算单个样本的损失
        f_x_nat=F.log_softmax(self.model(X_nat), dim=1)
        f_x_double_adv=F.softmax(self.model(X_double_adv), dim=1)
        
        
        loss_1=self.celoss(self.model(X_nat), Y)
        # print(loss_1)
        # print("paluse")
        
        loss_2=self.b*self.klloss(f_x_nat,f_x_double_adv)/len(Y)
        # print(loss_2)
        # print("paluse")
        
        loss_trades=torch.sum((loss_1+loss_2))
        
        loss_dar=self.y*prob_sum*self.klloss(f_x_nat, f_x_double_adv)/len(Y)
        # print(loss_dar)
        # print("paluse")
                
        # loss_adv = torch.sum((self.celoss(self.model(X_nat), Y))
        #     +(self.b*self.klloss(self.model(X_nat), self.model(X_double_adv)))#Loss TRADES
        #     +(self.y*prob_sum*self.klloss(self.model(X_nat), self.model(X_double_adv))))
        loss_adv=torch.sum(loss_trades+loss_dar)
        # print(loss_adv)
        # print("paluse")
        return loss_adv
    
    def DAR_loss(self,Y,X_nat,X_adv,X_double_adv):#拆分样本，最后重组
        loss=torch.tensor(0.0,requires_grad=True)
        P_y_X=self.prob(X_nat,Y)
        P_y_X_adv=self.prob(X_adv,Y)
        P_y_X_adv=P_y_X_adv.sub_(1).neg()
        prob_sum=(P_y_X*P_y_X_adv).sum()/len(Y)
        # print(prob_sum)
        loss=self.loss(Y,X_nat,X_double_adv,prob_sum)
        
        # print(loss)
        # print("paluse")
        return loss