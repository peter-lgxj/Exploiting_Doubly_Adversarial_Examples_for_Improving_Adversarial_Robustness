第一次做论文复现，代码写的很烂，请各位大佬轻喷。
部分代码参考了https://github.com/wanglouis49/pytorch-adversarial_box

原著为“EXPLOITING DOUBLY ADVERSARIAL EXAMPLES FOR IMPROVING ADVERSARIAL ROBUSTNESS”
论文出处：“https://ieeexplore.ieee.org/abstract/document/9897374”

文章观点是利用双对抗样本进行对抗训练来增强模型对于AutoAttack的对抗鲁棒性

文章提出的思路是：

1. 利用2次PGD-20生成双重对抗样本
2. 利用这些对抗样本训练一个分类器（采用resnet18）
3. 提出一种DAR的防御损失来优化模型参数

代码基于PyTorch实现，数据集为CIFAR-10。
CIFAR-10_adv_train.py用于对抗训练
black_box_test.py用于在干净样本上测试以及做适应性训练
